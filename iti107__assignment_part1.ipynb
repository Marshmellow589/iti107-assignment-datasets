{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107-2024S2/blob/main/session-3/yolo8_custom_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWSUqz7gPOF4"
   },
   "source": [
    "## Create an object detection dataset\n",
    "\n",
    "the dataset is relate to classification of fire fighting equipments and safety deviec such as fire extinguisher, helmelt,fire signage with total around 100 pictures, and one video which relate to sale product of fire fighting equipments.\n",
    "\n",
    "the pictures have been anoted by roboflow to lable with 'helmet',fire extighuisher and fire signage.\n",
    "\n",
    "the images have been download to dataset folder per Ultralytics training set requirments.\n",
    "### Raw Image Dataset\n",
    "\n",
    "\n",
    "There are total of 100 images.\n",
    "the images have been divided into both training and validation set.\n",
    " (e.g. 80%-20%, i.e. 59 images for train, and 15 for test).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_VTuEfec2YW"
   },
   "source": [
    "### Download Annotated Dataset\n",
    "\n",
    "To save you time for this lab, you can download a pre-annotated balloon dataset [here](https://github.com/nyp-sit/iti107-2024S2/raw/refs/heads/main/data/balloon_annotated_dataset.zip).\n",
    "\n",
    "We download and unzip to the directory called `datasets`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPFw8q28CnDP",
    "outputId": "774177c6-cc53-4bb5-e98a-891d040d48db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (3.1.24)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from gitpython) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from gitpython) (4.11.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython) (4.0.0)\n",
      "Repository cloned to datasets\n"
     ]
    }
   ],
   "source": [
    "# Install GitPython if not already installed\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "!pip install gitpython\n",
    "# Clone the repository using GitPython\n",
    "import git\n",
    "repo_url = \"https://github.com/Marshmellow589/iti107-assignment-datasets.git\"\n",
    "repo_dir = \"datasets\"\n",
    "git.Repo.clone_from(repo_url, repo_dir)\n",
    "print(f\"Repository cloned to {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0BTQ6QpZz3kP"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# import platform \n",
    "# !pip install --upgrade ultralytics\n",
    "# !!pip install ultralytics[default]\n",
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgyWGNT4-MLv"
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "YOLOv8 comes with different sizes of pretrained models: yolov8n, yolov8s, .... The differs in terms of their sizes, inference speeds and precision:\n",
    "\n",
    "<img src=\"https://github.com/nyp-sit/iti107-2024S2/blob/main/assets/yolo-models.png?raw=true\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "We will use the small pretrained model yolo8s and finetune it on our custom dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKnPWyDwUfvZ"
   },
   "source": [
    "### Setup the logging\n",
    "\n",
    "Ultralytics support logging to wandb, comet.ml and tensorboard, out of the box. Here we only enable wandb.\n",
    "\n",
    "You need to create an account at [wandb](https://wandb.ai) and get the API key from https://wandb.ai/authorize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Ultralytics settings reset to default values. This may be due to a possible problem with your settings or a recent ultralytics package update. \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\yinbo\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import platform  # Ensure the 'platform' module is imported\n",
    "import sys  # Used to reload modules\n",
    "import ultralytics  # Import the library\n",
    "\n",
    "# Force a reload of ultralytics\n",
    "sys.modules.pop('ultralytics', None)  # Remove from cache\n",
    "sys.modules.pop('ultralytics.yolo.v8', None)  # Remove a specific submodule\n",
    "import ultralytics  # Import ultralytics again to reload\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "\n",
    "settings.update({\"wandb\": True,\n",
    "                 \"comet.ml\": False,\n",
    "                 \"tensorboard\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq9gV4A1VHlq"
   },
   "source": [
    "### Training\n",
    "\n",
    "We specify the path to data.yaml file, and train with a batch size of 15, and we also save the checkpoint at each epoch (save_period=1). We assume here you are connected to a GPU, hence we can specify the device to use as `device=0` to select the first GPU.  We specify the project name as balloon, this will create a folder called `balloon` to store the weights and various training artifacts such as F1, PR curves, confusion matrics, training results (loss, mAP, etc).\n",
    "\n",
    "For a complete listing of train settings, you can see [here](https://docs.ultralytics.com/modes/train/#train-settings).\n",
    "\n",
    "You can also specify the type of data [augmentation](https://docs.ultralytics.com/modes/train/#augmentation-settings-and-hyperparameters)  you want as part of the train pipeline.\n",
    "\n",
    "You can monitor your training progress at wandb (the link is given in the train output below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation parameters \n",
    "augmentation_params = {'hsv_h': 0.015, # HSV-Hue augmentation \n",
    "                       'hsv_s': 0.7, # HSV-Saturation augmentation \n",
    "                       'hsv_v': 0.4, # HSV-Value augmentation \n",
    "                       'degrees': 0.0, # Image rotation (+/- deg) \n",
    "                       'translate': 0.1, # Image translation (+/- fraction) \n",
    "                       'scale': 0.5, # Image scale (+/- gain) \n",
    "                       # 'shear': 0.0, # Image shear (+/- deg) \n",
    "                       # 'perspective': 0.0, # Image perspective (+/- fraction), range 0-0.001 \n",
    "                       'flipud': 0.0, # Flip up-down (probability) \n",
    "                       # 'fliplr': 0.5, # Flip left-right (probability) \n",
    "                       # 'mosaic': 1.0, # Mosaic augmentation (probability) \n",
    "                       'mixup': 0.0, # Mixup augmentation (probability) \n",
    "                       # 'copy_paste': 0.0 # Copy-paste augmentation (probability) \n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "NwjnKk02x-cF",
    "outputId": "6d32bcae-6f5e-480b-cdbc-e9ff0d8ef717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 21.5M/21.5M [00:01<00:00, 20.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.46  Python-3.8.18 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=datasets/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=1, cache=False, device=cpu, workers=8, project=iti107_assignment, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=iti107_assignment\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\pythontest\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,137,148 parameters, 11,137,132 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "WARNING  Comet installed but not initialized correctly, not logging this run. Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY \n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\train\\labels... 41 images, 0 ba\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\valid\\labels... 10 images, 0 back\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to iti107_assignment\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/07 15:10:48 INFO mlflow.tracking.fluent: Experiment with name 'iti107_assignment' does not exist. Creating a new experiment.\n",
      "2024/12/07 15:10:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2024/12/07 15:10:50 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2024/12/07 15:10:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m No Comet API Key was found, creating an offline experiment. Set up your API Key to get the full Comet experience https://www.comet.com/docs/python-sdk/advanced/#python-configuration\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Using 'e:\\\\Anaconda\\\\envs\\\\00.NYP course\\\\itit107-spdc2\\\\assignment-iti107\\\\.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(0bcac85d4b9548c88a583a49909b8324) to runs\\mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs\\mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1miti107_assignment\\train\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in 'e:\\\\Anaconda\\\\envs\\\\00.NYP course\\\\itit107-spdc2\\\\assignment-iti107' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "       1/30         0G      1.597       4.35      1.782         28        640: 100%|██████████| 3/3 [00:38<00:00, 12.79\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.154      0.238      0.125     0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.621       3.34      1.864         25        640: 100%|██████████| 3/3 [00:34<00:00, 11.48\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23       0.87       0.28      0.355      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.285      2.578      1.549         36        640: 100%|██████████| 3/3 [00:35<00:00, 11.86\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.779      0.461      0.442       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.192      2.137       1.39         23        640: 100%|██████████| 3/3 [00:34<00:00, 11.57\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 2.500s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.671      0.262      0.329      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G      1.037       1.67      1.338         32        640: 100%|██████████| 3/3 [00:35<00:00, 11.81\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.707      0.392      0.481      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G     0.9523      1.686      1.369         28        640: 100%|██████████| 3/3 [00:34<00:00, 11.46\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23       0.68      0.613      0.635      0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G       1.04      1.439      1.314         36        640: 100%|██████████| 3/3 [00:34<00:00, 11.66\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.823      0.589      0.608      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G     0.9802      1.414      1.301         30        640: 100%|██████████| 3/3 [00:34<00:00, 11.61\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.886      0.626      0.647      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.091      1.412      1.361         27        640: 100%|██████████| 3/3 [00:35<00:00, 11.85\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.856      0.584      0.689      0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G      1.047       1.27      1.347         38        640: 100%|██████████| 3/3 [00:35<00:00, 11.67\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.883      0.596      0.694      0.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G      1.028      1.287      1.354         25        640: 100%|██████████| 3/3 [00:35<00:00, 11.93\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23       0.94      0.591       0.77      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G     0.9764      1.196       1.34         23        640: 100%|██████████| 3/3 [00:35<00:00, 11.81\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.611      0.823      0.824       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G     0.9547      1.152      1.233         24        640: 100%|██████████| 3/3 [00:37<00:00, 12.66\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.618      0.726      0.697      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      0.785      1.079      1.164         26        640: 100%|██████████| 3/3 [00:35<00:00, 11.71\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.589      0.729       0.68      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G     0.9111      1.087      1.213         32        640: 100%|██████████| 3/3 [00:37<00:00, 12.55\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.851      0.565      0.664      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.031      1.085      1.333         29        640: 100%|██████████| 3/3 [00:34<00:00, 11.66\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.958      0.612      0.724      0.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G     0.9766     0.9741      1.255         32        640: 100%|██████████| 3/3 [00:35<00:00, 11.87\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.758      0.657      0.613      0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G     0.9126     0.9249      1.188         29        640: 100%|██████████| 3/3 [00:35<00:00, 11.74\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23       0.79      0.614      0.588      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G     0.8401     0.9127      1.185         26        640: 100%|██████████| 3/3 [00:35<00:00, 11.78\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.865      0.673        0.7      0.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G     0.9139      1.025      1.273         24        640: 100%|██████████| 3/3 [00:35<00:00, 11.68\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.836      0.708      0.735      0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G     0.8183       1.03      1.215         14        640: 100%|██████████| 3/3 [00:35<00:00, 11.72\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.894      0.665      0.708      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      0.909      1.122      1.293         14        640: 100%|██████████| 3/3 [00:34<00:00, 11.52\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.772      0.663      0.671      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G       0.76     0.9105       1.19         11        640: 100%|██████████| 3/3 [00:35<00:00, 11.69\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.498      0.708       0.63      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G     0.8254     0.8415      1.177         16        640: 100%|██████████| 3/3 [00:34<00:00, 11.63\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.527       0.75      0.655      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G     0.7176     0.8306      1.174         15        640: 100%|██████████| 3/3 [00:34<00:00, 11.58\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23       0.54      0.792      0.699      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G      0.761      0.817       1.19         14        640: 100%|██████████| 3/3 [00:35<00:00, 11.71\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.531      0.738      0.619      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G     0.7306     0.8134      1.148         14        640: 100%|██████████| 3/3 [00:35<00:00, 11.90\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.561      0.768      0.655      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G        0.7     0.7852      1.113         11        640: 100%|██████████| 3/3 [00:36<00:00, 12.28\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.556      0.732      0.659      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G     0.7011     0.7493      1.246         11        640: 100%|██████████| 3/3 [00:35<00:00, 11.68\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.556      0.732      0.659      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G     0.6641     0.7251      1.149         15        640: 100%|██████████| 3/3 [00:35<00:00, 11.80\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.533      0.768      0.665      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 0.332 hours.\n",
      "Optimizer stripped from iti107_assignment\\train\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from iti107_assignment\\train\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating iti107_assignment\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.46  Python-3.8.18 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "Model summary (fused): 168 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.611      0.823      0.825      0.528\n",
      "   extinguisher-helmet          2          3          1      0.601      0.705      0.626\n",
      "     fire extinguisher          4          7      0.599          1      0.924      0.552\n",
      "          fire signage          5          6      0.365      0.833      0.811      0.486\n",
      "                helmet          3          7      0.479      0.857      0.861      0.447\n",
      "Speed: 3.0ms preprocess, 212.6ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1miti107_assignment\\train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml OfflineExperiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : [OfflineExperiment will get URL after upload]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [61]               : (2.5e-05, 0.0002966875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [61]               : (2.5e-05, 0.0002966875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [61]               : (2.5e-05, 0.0002966875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [31]     : (0.1253, 0.8253728317659352)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [31]  : (0.07206, 0.53013)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95B [31]    : (0.07206, 0.53013)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50B [31]       : (0.1253, 0.8253728317659352)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [31] : (0.15377, 0.95806)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precisionB [31]   : (0.15377, 0.95806)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [31]    : (0.2381, 0.8227690779019218)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recallB [31]      : (0.2381, 0.8227690779019218)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 28.653\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 11137148\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 254.28\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [60]       : (0.66407, 1.62099)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [60]       : (0.72514, 4.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [60]       : (1.11311, 1.86399)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [60]         : (1.35827, 1.68653)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [60]         : (1.60492, 5.1212)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [60]         : (1.77274, 2.1582)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from       : MLFlow auto-logger\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name               : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_experiment : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : datasets/data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : cpu\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 30\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8s.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : iti107_assignment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : iti107_assignment\\train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images                       : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 30 (1.84 GB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still saving offline stats to messages file before program termination (may take up to 120 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Begin archiving the offline data.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m To upload this offline experiment, run:\n",
      "    comet upload e:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\.cometml-runs\\a025c9f764b94418be1134d45659abcb.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs\\mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")  # Load a pre-trained YOLO model\n",
    "result = model.train(data=\"datasets/data.yaml\",\n",
    "                     epochs=30,\n",
    "                     save_period=1,\n",
    "                     batch=16,\n",
    "                     device='cpu',\n",
    "                     project='iti107_assignment',\n",
    "                     **augmentation_params, # Apply data augmentation parameters,\n",
    "                     plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59BONHriXz3H"
   },
   "source": [
    "You can see the various graphs in  dashboard, for example:\n",
    "\n",
    "*metrics*\n",
    "\n",
    "<img src=\"https://github.com/nyp-sit/iti107-2024S2/blob/main/assets/wandb-metrics.png?raw=true\"/>\n",
    "\n",
    "*Train and validation loss*\n",
    "\n",
    "<img src=\"https://github.com/nyp-sit/iti107-2024S2/blob/main/assets/wandb-loss.png?raw=true\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3QivGwNaY3l"
   },
   "source": [
    "You can go to the folder `iti107_assignment-->train-->weights` and you will files like epoch0.pt, epoch1.pt, .... and also best.pt.\n",
    "The epoch0.pt, epoch1.pt are the checkpoints that are saved every period (in our case, we specify period as 1 epoch).  The best.pt contains the best checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-PxfxzMbAOS"
   },
   "source": [
    "We can run the best model (using the best checkpoint) against the validation dataset to see the overall model performance on validation set.  \n",
    "\n",
    "You should see around `0.88` for `mAP50`, and `0.78` for `mAP50-95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n6GRS5f2f05",
    "outputId": "37e7e8a0-a794-4033-e2c7-1b49fd9885f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.46  Python-3.8.18 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "Model summary (fused): 168 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\valid\\labels.cache... 10 images, \u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         23      0.611      0.823      0.825      0.528\n",
      "   extinguisher-helmet          2          3          1      0.601      0.705      0.626\n",
      "     fire extinguisher          4          7      0.599          1      0.924      0.552\n",
      "          fire signage          5          6      0.365      0.833      0.811      0.486\n",
      "                helmet          3          7      0.479      0.857      0.861      0.447\n",
      "Speed: 2.2ms preprocess, 185.9ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"iti107_assignment/train/weights/best.pt\")\n",
    "validation_results = model.val(data=\"datasets/data.yaml\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bio2cKcnb-Z-"
   },
   "source": [
    "## Export and Deployment\n",
    "\n",
    "Your model is in pytorch format (.pt). You can export the model to various format, e.g. TorchScript, ONNX, OpenVINO, TensorRT, etc. depending on your use case, and deployment platform (e.g. CPU or GPU, etc)\n",
    "\n",
    "You can see the list of [supported formats](https://docs.ultralytics.com/modes/export/#export-formats)  and the option they support in terms of further optimization (such as imagesize, int8, half-precision, etc) in the ultralytics site.\n",
    "\n",
    "Ultralytics provide a utility function to benchmark your model using different supported formats automatically. You can uncomment the code in the following code cell to see the benchmark result. If you are benchmarking for CPU only, the change the `device=0` to `device='cpu'`.  \n",
    "\n",
    "**Beware: it will take quite a while to complete the benchmark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Usgkfg87bZBO"
   },
   "outputs": [],
   "source": [
    "# from ultralytics.utils.benchmarks import benchmark\n",
    "\n",
    "# # Benchmark on GPU (device=0 means the 1st GPU device)\n",
    "# benchmark(model=\"balloon/train/weights/best.pt\", data=\"datasets/data.yaml\", imgsz=640, half=False, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openvino in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (2024.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from openvino) (1.24.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from openvino) (2024.5.0)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from openvino) (24.1)\n",
      "Requirement already satisfied: nncf==2.13.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (4.19.2)\n",
      "Requirement already satisfied: jstyleson>=0.0.2 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (0.0.2)\n",
      "Requirement already satisfied: natsort>=7.1.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (8.4.0)\n",
      "Requirement already satisfied: networkx<=3.3,>=2.6 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (2.6.3)\n",
      "Requirement already satisfied: ninja<1.12,>=1.10.0.post2 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (1.11.1.2)\n",
      "Requirement already satisfied: numpy<1.27,>=1.19.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (1.24.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (24.1)\n",
      "Requirement already satisfied: pandas<2.3,>=1.1.5 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (1.4.4)\n",
      "Requirement already satisfied: psutil in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (5.9.0)\n",
      "Requirement already satisfied: pydot<3.0.0,>=1.4.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (2.0.0)\n",
      "Requirement already satisfied: pymoo>=0.6.0.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (0.6.1.2)\n",
      "Requirement already satisfied: rich>=13.5.2 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (13.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (1.10.1)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from nncf==2.13.0) (4.66.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from jsonschema>=3.2.0->nncf==2.13.0) (23.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from jsonschema>=3.2.0->nncf==2.13.0) (6.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from jsonschema>=3.2.0->nncf==2.13.0) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from jsonschema>=3.2.0->nncf==2.13.0) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from jsonschema>=3.2.0->nncf==2.13.0) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from jsonschema>=3.2.0->nncf==2.13.0) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pandas<2.3,>=1.1.5->nncf==2.13.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pandas<2.3,>=1.1.5->nncf==2.13.0) (2024.1)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pydot<3.0.0,>=1.4.1->nncf==2.13.0) (3.0.9)\n",
      "Requirement already satisfied: matplotlib>=3 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pymoo>=0.6.0.1->nncf==2.13.0) (3.5.3)\n",
      "Requirement already satisfied: autograd>=1.4 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pymoo>=0.6.0.1->nncf==2.13.0) (1.7.0)\n",
      "Requirement already satisfied: cma==3.2.2 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pymoo>=0.6.0.1->nncf==2.13.0) (3.2.2)\n",
      "Requirement already satisfied: alive-progress in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pymoo>=0.6.0.1->nncf==2.13.0) (3.1.5)\n",
      "Requirement already satisfied: dill in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pymoo>=0.6.0.1->nncf==2.13.0) (0.3.8)\n",
      "Requirement already satisfied: Deprecated in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from pymoo>=0.6.0.1->nncf==2.13.0) (1.2.15)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from rich>=13.5.2->nncf==2.13.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from rich>=13.5.2->nncf==2.13.0) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from rich>=13.5.2->nncf==2.13.0) (4.11.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from scikit-learn>=0.24.0->nncf==2.13.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from scikit-learn>=0.24.0->nncf==2.13.0) (3.5.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from tqdm>=4.54.1->nncf==2.13.0) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema>=3.2.0->nncf==2.13.0) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf==2.13.0) (0.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf==2.13.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf==2.13.0) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf==2.13.0) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf==2.13.0) (9.3.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<2.3,>=1.1.5->nncf==2.13.0) (1.15.0)\n",
      "Requirement already satisfied: about-time==4.2.1 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from alive-progress->pymoo>=0.6.0.1->nncf==2.13.0) (4.2.1)\n",
      "Requirement already satisfied: grapheme==0.6.0 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from alive-progress->pymoo>=0.6.0.1->nncf==2.13.0) (0.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\anaconda\\envs\\pythontest\\lib\\site-packages (from Deprecated->pymoo>=0.6.0.1->nncf==2.13.0) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install openvino\n",
    "!pip install nncf==2.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD-vKnPYfBu3"
   },
   "source": [
    "\n",
    "In the following code, we export it as OpenVINO. OpenVINO is optimized for inference on Intel CPUs and since we will use the model later on to do inference on local Windows machine (which runs Intel chip), we will export it as OpenVINO format. We also specify using int8 quantization, which results in faster inference, at the cost of accuracy.\n",
    "\n",
    "For more information on OpenVINO, go to the [official documentation](https://docs.openvino.ai/2024/index.html).\n",
    "\n",
    "After export, you can find the openvino model in `iti107_assignment\\train\\weights\\best_openvino_model` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b51ed7d56f594407b6f3a341f5c3c7cb",
      "e9631d16d2ce45eb90d693b72f5d42ee",
      "a80a701d3aeb4047955d05b9e365c653",
      "f32e82c784934886aa6b35a66e13c0a0"
     ]
    },
    "id": "S6PDNf5NaPch",
    "outputId": "d38d2247-6485-4d16-c63b-b93a8c3495d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.46  Python-3.8.18 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "WARNING  INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
      "Model summary (fused): 168 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'iti107_assignment\\train\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 8, 8400) (21.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['openvino>=2024.5.0'] not found, attempting AutoUpdate...\n",
      "Retry 1/2 failed: Command 'pip install --no-cache-dir \"openvino>=2024.5.0\" ' returned non-zero exit status 1.\n",
      "Retry 2/2 failed: Command 'pip install --no-cache-dir \"openvino>=2024.5.0\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install --no-cache-dir \"openvino>=2024.5.0\" ' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.0.0-14509-34caeefd078-releases/2024/0...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['nncf>=2.14.0'] not found, attempting AutoUpdate...\n",
      "Retry 1/2 failed: Command 'pip install --no-cache-dir \"nncf>=2.14.0\" ' returned non-zero exit status 1.\n",
      "Retry 2/2 failed: Command 'pip install --no-cache-dir \"nncf>=2.14.0\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install --no-cache-dir \"nncf>=2.14.0\" ' returned non-zero exit status 1.\n",
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, openvino\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n",
      "\n",
      "Dataset 'coco8.yaml' images not found , missing path 'E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\coco8\\images\\val'\n",
      "Downloading https://ultralytics.com/assets/coco8.zip to 'E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\coco8.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 433k/433k [00:00<00:00, 3.74MB/s]\n",
      "Unzipping E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\coco8.zip to E:\\Anaconda\\envs\\00.NYP "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (3.1s), saved to \u001b[1mE:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\coco8\\labels\\val... 4 images, 0 backgr"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New cache created: E:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\datasets\\coco8\\labels\\val.cache\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m WARNING  >300 images recommended for INT8 calibration, found 4 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:25 ignored nodes were found by patterns in the NNCFGraph\n",
      "INFO:nncf:1 ignored nodes were found by types in the NNCFGraph\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 162 __module.model.22.dfl/aten::view/Reshape\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 163 __module.model.22/aten::sigmoid/Sigmoid\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 173 __module.model.22.dfl/aten::transpose/Transpose\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 182 __module.model.22.dfl/aten::softmax/Softmax\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 190 __module.model.22.dfl.conv/aten::_convolution/Convolution\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 189 __module.model.22.dfl/aten::view/Reshape_1\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 203 __module.model.22/aten::sub/Subtract\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 204 __module.model.22/aten::add/Add\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 212 __module.model.22/aten::add/Add_1\n",
      "221 __module.model.22/aten::div/Divide\n",
      "\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 213 __module.model.22/aten::sub/Subtract_1\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 229 __module.model.22/aten::mul/Multiply\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7884d0776dd4070a1d9fdacb217f0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcedafe1eb6642269bd9335513d5506b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  36.1s, saved as 'iti107_assignment\\train\\weights\\best_int8_openvino_model\\' (11.2 MB)\n",
      "\n",
      "Export complete (36.8s)\n",
      "Results saved to \u001b[1mE:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\iti107_assignment\\train\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=iti107_assignment\\train\\weights\\best_int8_openvino_model imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=iti107_assignment\\train\\weights\\best_int8_openvino_model imgsz=640 data=datasets/data.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = YOLO(\"iti107_assignment/train/weights/best.pt\")\n",
    "exported_path = model.export(format=\"openvino\", int8=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11lPCYrfMKN"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's test our model on some sample pictures. You can optionally specify the confidence threshold (e.g. `conf=0.5`), and the IoU (e.g. `iou=0.6`) for the NMS. The model will only output the bounding boxes of those detection that exceeds the confidence threshould and the IoU threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ziKNFammhMxv",
    "outputId": "21f66b65-f0a0-43cd-d5ec-9a09dcdfdf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iti107_assignment\\train\\weights\\best_int8_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "\n",
      "image 1/1 e:\\Anaconda\\envs\\00.NYP course\\itit107-spdc2\\assignment-iti107\\test_pic5.png: 640x640 4 fire extinguishers, 2 fire signages, 1 helmet, 40.0ms\n",
      "Speed: 8.9ms preprocess, 40.0ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'extinguisher-helmet', 1: 'fire extinguisher', 2: 'fire signage', 3: 'helmet'}\n",
      "obb: None\n",
      "orig_img: array([[[ 98, 101, 107],\n",
      "        [ 98, 100, 108],\n",
      "        [ 98, 100, 109],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 97, 100, 106],\n",
      "        [ 96,  99, 106],\n",
      "        [ 96,  98, 107],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 96,  98, 104],\n",
      "        [ 96,  98, 105],\n",
      "        [ 96,  98, 105],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (676, 1238)\n",
      "path: 'e:\\\\Anaconda\\\\envs\\\\00.NYP course\\\\itit107-spdc2\\\\assignment-iti107\\\\test_pic5.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 8.867502212524414, 'inference': 40.004730224609375, 'postprocess': 7.433414459228516}\n"
     ]
    }
   ],
   "source": [
    "# import ultralytics\n",
    "# from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# source = 'https://raw.githubusercontent.com/nyp-sit/iti107-2024S2/refs/heads/main/session-3/samples/sample_balloon.jpeg'\n",
    "source = './test_pic5.png'\n",
    "model = YOLO(\"iti107_assignment/train/weights/best_int8_openvino_model\", task='detect')\n",
    "result = model(source, conf=0.4, iou=0.4)\n",
    "\n",
    "# Visualize the results\n",
    "for i, r in enumerate(result):\n",
    "    print(r)\n",
    "    # Plot results image\n",
    "    im_bgr = r.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "\n",
    "    # Show results to screen (in supported environments)\n",
    "    r.show()\n",
    "\n",
    "    # Save results to disk\n",
    "    r.save(filename=f\"results{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a80a701d3aeb4047955d05b9e365c653": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f32e82c784934886aa6b35a66e13c0a0",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applying Fast Bias correction <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #0068b5; text-decoration-color: #0068b5\">63/63</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:04</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:00</span>\n</pre>\n",
         "text/plain": "Applying Fast Bias correction \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[38;2;0;104;181m63/63\u001b[0m • \u001b[38;2;0;104;181m0:00:04\u001b[0m • \u001b[38;2;0;104;181m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "b51ed7d56f594407b6f3a341f5c3c7cb": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_e9631d16d2ce45eb90d693b72f5d42ee",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Statistics collection <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #0068b5; text-decoration-color: #0068b5\">4/4</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:03</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:00</span>\n</pre>\n",
         "text/plain": "Statistics collection \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[38;2;0;104;181m4/4\u001b[0m • \u001b[38;2;0;104;181m0:00:03\u001b[0m • \u001b[38;2;0;104;181m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "e9631d16d2ce45eb90d693b72f5d42ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f32e82c784934886aa6b35a66e13c0a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
